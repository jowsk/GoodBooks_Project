{"cells":[{"cell_type":"markdown","metadata":{},"source":["This notebook is a implementation of LightGCN model for collaborating filtering. The model is based on the paper [LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/abs/2002.02126) by Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang."]},{"cell_type":"code","execution_count":142,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718040869881,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"Y9fonQcxt3do"},"outputs":[],"source":["# Standard library imports\n","import random\n","import time\n","\n","# Third-party imports\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_colwidth', None)\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch_geometric\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.utils import degree\n","\n","from tqdm.notebook import tqdm\n","from sklearn import preprocessing as pp"]},{"cell_type":"code","execution_count":144,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718040869882,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"b4pKT5jUt3pz"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["### Data Importation"]},{"cell_type":"code","execution_count":145,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":1422,"status":"ok","timestamp":1718040871908,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"D13_omigmeOi","outputId":"f1449da8-ba71-494e-88fd-36ae3d68e6bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["4781183\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1760,\n        \"min\": 26,\n        \"max\": 4081,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          260\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"},"text/html":["\n","  <div id=\"df-7f1e4b29-6b1f-438e-81f5-3a3a9c0a1a03\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>item_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>4081</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>260</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2318</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>26</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>315</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f1e4b29-6b1f-438e-81f5-3a3a9c0a1a03')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7f1e4b29-6b1f-438e-81f5-3a3a9c0a1a03 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7f1e4b29-6b1f-438e-81f5-3a3a9c0a1a03');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dcc26310-5fe5-4bc8-8380-33d2b4d04294\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcc26310-5fe5-4bc8-8380-33d2b4d04294')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dcc26310-5fe5-4bc8-8380-33d2b4d04294 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["   user_id  item_id  rating\n","0        2     4081       4\n","1        2      260       5\n","2        2     2318       3\n","3        2       26       4\n","4        2      315       3"]},"metadata":{},"output_type":"display_data"}],"source":["columns_name=['user_id','item_id','rating']\n","df = pd.read_csv('./drive/MyDrive/Colab/NML/data/ratings_train.csv', names=columns_name, header=0)\n","print(len(df))\n","df.dropna(inplace=True)\n","display(df.head(5))"]},{"cell_type":"markdown","metadata":{},"source":["Because the input data is too large we keep the ratings given by the first **30000 users** only for the positive ratings, we can keep all the ratings for the negative ratings as they are less than the positive ratings."]},{"cell_type":"code","execution_count":146,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1718040871909,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"hUW7CvbUJaSu"},"outputs":[],"source":["df_pos = df[df['user_id'] < 30000] "]},{"cell_type":"markdown","metadata":{"id":"BzX3-JClrcCx"},"source":["We split the ratings into **good** and **bad** ratings with a threshold of 3 on the scale of ratings from 1 to 5."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1718040871909,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"j0vvQB9Kmea7","outputId":"49a3576b-2705-4851-f84d-8928d839f183"},"outputs":[],"source":["df = df[df['rating'] < 3]\n","df_pos = df_pos[df_pos['rating'] >= 3]"]},{"cell_type":"code","execution_count":149,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1718040871909,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"yvuk3tEomrQI","outputId":"16a8e3c5-fa5b-4e81-bb8d-6d59768f9fee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rating Distribution\n"]},{"data":{"text/plain":["rating\n","1     99633\n","2    287396\n","Name: rating, dtype: int64"]},"execution_count":149,"metadata":{},"output_type":"execute_result"}],"source":["# What's the distribution of badly rated movies?\n","print(\"Rating Distribution\")\n","df.groupby(['rating'])['rating'].count()"]},{"cell_type":"markdown","metadata":{},"source":["We put this ratings to train positive and negative models.\n","\n","We also import the test dataset of ratings that will be used to evaluate the models."]},{"cell_type":"code","execution_count":150,"metadata":{"executionInfo":{"elapsed":525,"status":"ok","timestamp":1718040872428,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"7q_oqwEZ9axN"},"outputs":[],"source":["train_df = df\n","train_df_pos = df_pos\n","test_df = pd.read_csv('./drive/MyDrive/Colab/NML/data/ratings_test.csv', names=columns_name, header=0)"]},{"cell_type":"code","execution_count":151,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718040872428,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"50eSoP3qmrbJ","outputId":"131e543a-e65e-4861-dcc4-111bca37a6c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Size  :  387029\n","Test Size :  1195296\n"]}],"source":["print(\"Train Size  : \", len(train_df))\n","print(\"Test Size : \", len (test_df))"]},{"cell_type":"markdown","metadata":{"id":"g0bHVYGjrTcL"},"source":["Since we performed the train/test randomly on the interactions, not all users and items may be present in the training sets. We will relabel all of users and items to ensure the highest label is the number of users and items, respectively."]},{"cell_type":"code","execution_count":152,"metadata":{"executionInfo":{"elapsed":474,"status":"ok","timestamp":1718040872899,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"QXi90opJmriQ"},"outputs":[],"source":["le_user = pp.LabelEncoder()\n","le_item = pp.LabelEncoder()\n","le_user_pos = pp.LabelEncoder()\n","le_item_pos = pp.LabelEncoder()\n","train_df['user_id_idx'] = le_user.fit_transform(train_df['user_id'].values)\n","train_df['item_id_idx'] = le_item.fit_transform(train_df['item_id'].values)\n","train_df_pos['user_id_idx'] = le_user_pos.fit_transform(train_df_pos['user_id'].values)\n","train_df_pos['item_id_idx'] = le_item_pos.fit_transform(train_df_pos['item_id'].values)"]},{"cell_type":"markdown","metadata":{},"source":["Then we keep only the users and items that are present in the training set for the test set."]},{"cell_type":"code","execution_count":153,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718040872900,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"KtRmOkoDmem_","outputId":"cc85354b-4581-4aaa-9437-77128d195187"},"outputs":[{"name":"stdout","output_type":"stream","text":["46334 9920\n","618861\n"]}],"source":["train_user_ids = train_df['user_id'].unique()\n","train_item_ids = train_df['item_id'].unique()\n","\n","train_user_ids_pos = train_df_pos['user_id'].unique()\n","train_item_ids_pos = train_df_pos['item_id'].unique()\n","\n","print(len(train_user_ids), len(train_item_ids))\n","\n","test_df = test_df[\n","  (test_df['user_id'].isin(train_user_ids)) & \\\n","  (test_df['item_id'].isin(train_item_ids)) & \\\n","  (test_df['user_id'].isin(train_user_ids_pos)) & \\\n","  (test_df['item_id'].isin(train_item_ids_pos))\n","]\n","print(len(test_df))"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718040872900,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"9fKAfWyCm5eY"},"outputs":[],"source":["test_df['user_id_idx'] = le_user.transform(test_df['user_id'].values)\n","test_df['item_id_idx'] = le_item.transform(test_df['item_id'].values)"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718040872900,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"-WOF-cOAm5iO","outputId":"45278ff0-379e-49b8-b2b2-e63bedbb0603"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unique Users :  46334\n","Number of unique Items :  9920\n"]}],"source":["n_users = train_df['user_id_idx'].nunique()\n","n_items = train_df['item_id_idx'].nunique()\n","n_users_pos = train_df_pos['user_id_idx'].nunique()\n","n_items_pos = train_df_pos['item_id_idx'].nunique()\n","print(\"Number of Unique Users : \", n_users)\n","print(\"Number of unique Items : \", n_items)"]},{"cell_type":"markdown","metadata":{},"source":["We need to define the notion of positive and negative edges: `positive edges` are those that exist in the graph and `negative edges` are those that don’t. In our bipartite graph, we can define for user u the set of all positive edges containing u, E(u) and the set of all negative edges containing u, E_neg(u)."]},{"cell_type":"code","execution_count":156,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1275,"status":"ok","timestamp":1718040874171,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"NQRGy-CJnOkg","outputId":"5ec1b64e-e462-4c27-fcb1-e8d881e2d99e"},"outputs":[{"data":{"text/plain":["(tensor([   54,  5504,  8609, 13425, 13711, 16523, 21233, 22976, 25007, 29993,\n","         34542, 38208, 39803, 40889, 41329, 41991]),\n"," tensor([46359, 55735, 50415, 54228, 46373, 53006, 47745, 47397, 48375, 46541,\n","         46355, 49148, 50049, 46981, 46843, 46336]),\n"," tensor([54769, 55895, 53351, 47195, 46392, 53826, 49875, 48666, 53383, 53586,\n","         46736, 50124, 55747, 51199, 48604, 54088]))"]},"execution_count":156,"metadata":{},"output_type":"execute_result"}],"source":["def data_loader(data, batch_size, n_usr, n_itm):\n","\n","    def sample_neg(x):\n","        while True:\n","            neg_id = random.randint(0, n_itm - 1)\n","            if neg_id not in x:\n","                return neg_id\n","\n","    interected_items_df = data.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n","    indices = [x for x in range(n_usr)]\n","\n","    if n_usr < batch_size:\n","        users = [random.choice(indices) for _ in range(batch_size)]\n","    else:\n","        users = random.sample(indices, batch_size)\n","    users.sort()\n","    users_df = pd.DataFrame(users,columns = ['users'])\n","\n","    interected_items_df = pd.merge(interected_items_df, users_df, how = 'right', left_on = 'user_id_idx', right_on = 'users')\n","    pos_items = interected_items_df['item_id_idx'].apply(lambda x : random.choice(x)).values\n","    neg_items = interected_items_df['item_id_idx'].apply(lambda x: sample_neg(x)).values\n","\n","    return (\n","        torch.LongTensor(list(users)).to(device),\n","        torch.LongTensor(list(pos_items)).to(device) + n_usr,\n","        torch.LongTensor(list(neg_items)).to(device) + n_usr\n","    )\n","\n","data_loader(train_df, 16, n_users, n_items)"]},{"cell_type":"markdown","metadata":{"id":"vjHZg1Eu-MKs"},"source":["## Edge Index\n","\n","PyG represents graphs as sparse lists of node pairs. Since our graph is undirected, we need to include each edge twice, once for the edges from the users to the items and vice-versa.\n","\n","Similar to above, we add `n_users` to the item tensor to ensure that every node in the graph has a unique identifier."]},{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1718040874172,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"O3BkGyV9pkce"},"outputs":[],"source":["array_tr_user = np.array(train_df.user_id_idx)\n","array_tr_item = np.array(train_df.item_id_idx)\n","u_t = torch.LongTensor(array_tr_user)\n","i_t = torch.LongTensor(array_tr_item) + n_users\n","\n","array_tr_user_pos = np.array(train_df_pos.user_id_idx)\n","array_tr_item_pos = np.array(train_df_pos.item_id_idx)\n","u_t_pos = torch.LongTensor(array_tr_user_pos)\n","i_t_pos = torch.LongTensor(array_tr_item_pos) + n_users_pos\n","\n","train_edge_index = torch.stack((\n","  torch.cat([u_t, i_t]),\n","  torch.cat([i_t, u_t])\n",")).to(device)\n","\n","train_edge_index_pos = torch.stack((\n","  torch.cat([u_t_pos, i_t_pos]),\n","  torch.cat([i_t_pos, u_t_pos])\n",")).to(device)"]},{"cell_type":"markdown","metadata":{"id":"_RxDUYJ2sXJe"},"source":["Let's confirm that the first and last edges match the middle two edges, but with the order of nodes swapped."]},{"cell_type":"code","execution_count":158,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1718040874172,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"Mq4NVs0_nOxh","outputId":"a7987fe0-99f6-4e1a-cb56-14174f6071f2"},"outputs":[{"data":{"text/plain":["(tensor([54440, 43722]), tensor([    3, 46588]))"]},"execution_count":158,"metadata":{},"output_type":"execute_result"}],"source":["train_edge_index[:,-1], train_edge_index[:, 0]"]},{"cell_type":"code","execution_count":159,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1718040874173,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"_gwESDz-qgw2","outputId":"67b6a1b8-9a79-4ab3-a8fd-408cd7ed28ef"},"outputs":[{"data":{"text/plain":["(tensor([43722, 54440]), tensor([46588,     3]))"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["train_edge_index[:, len(train_df)-1], train_edge_index[:, len(train_df)]"]},{"cell_type":"markdown","metadata":{"id":"49WD8SryyUds"},"source":["### LightGCN Convolutional Layer\n","\n","The LightGCN architecture is governed by the following rules:\n","\n","$$e_{u}^{(k+1)} = \\sum\\limits_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}}e^{(k)}_i$$\n","\n","$$e_{i}^{(k+1)} = \\sum\\limits_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}}e^{(k)}_u$$\n","In essence, the embedding for each node after a single LightGCN layer is the sum of the synthetic normalized embeddings of it's neighbors before the layer."]},{"cell_type":"code","execution_count":160,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1718040874173,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"-aTMoHisNIh_"},"outputs":[],"source":["class LightGCNConv(MessagePassing):\n","  def __init__(self, **kwargs):\n","    super().__init__(aggr='add')\n","\n","  def forward(self, x, edge_index):\n","    # Compute normalization\n","    from_, to_ = edge_index\n","    deg = degree(to_, x.size(0), dtype=x.dtype)\n","    deg_inv_sqrt = deg.pow(-0.5)\n","    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n","\n","    # Start propagating messages (no update after aggregation)\n","    return self.propagate(edge_index, x=x, norm=norm)\n","\n","  def message(self, x_j, norm):\n","    return norm.view(-1, 1) * x_j"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGLYDuxzaPjH"},"outputs":[],"source":["class RecSysGNN(nn.Module):\n","  def __init__(\n","      self,\n","      latent_dim,\n","      num_layers,\n","      num_users,\n","      num_items,\n","      model, # 'LightGCN'\n","  ):\n","    super(RecSysGNN, self).__init__()\n","\n","    self.model = model\n","    self.embedding = nn.Embedding(num_users + num_items, latent_dim)\n","\n","    self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))\n","\n","    self.init_parameters()\n","\n","\n","  def init_parameters(self):\n","    # Authors of LightGCN report higher results with normal initialization\n","    nn.init.normal_(self.embedding.weight, std=0.1)\n","\n","  def forward(self, edge_index):\n","\n","    emb0 = self.embedding.weight\n","    embs = [emb0]\n","\n","    emb = emb0\n","    for conv in self.convs:\n","      emb = conv(x=emb, edge_index=edge_index)\n","      print('emb size conv', emb.shape)\n","      embs.append(emb)\n","\n","    out = (torch.mean(torch.stack(embs, dim=0), dim=0))\n","\n","    return emb0, out\n","\n","\n","  def encode_minibatch(self, users, pos_items, neg_items, edge_index):\n","    emb0, out = self(edge_index)\n","    return (\n","        out[users],\n","        out[pos_items],\n","        out[neg_items],\n","        emb0[users],\n","        emb0[pos_items],\n","        emb0[neg_items]\n","    )"]},{"cell_type":"markdown","metadata":{"id":"dyqEQ6kfCY5V"},"source":["## Loss function and metrics\n","\n","We implement both the Bayesian Personalized Ranking loss function for a single minibatch of users, positive items, and negative items, as well as the precision K and recall K metrics."]},{"cell_type":"code","execution_count":164,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718040874174,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"bwrPmvXPow5q"},"outputs":[],"source":["def compute_bpr_loss(users, users_emb, pos_emb, neg_emb, user_emb0,  pos_emb0, neg_emb0):\n","  # compute loss from initial embeddings, used for regulization\n","  reg_loss = (1 / 2) * (\n","    user_emb0.norm().pow(2) +\n","    pos_emb0.norm().pow(2)  +\n","    neg_emb0.norm().pow(2)\n","  ) / float(len(users))\n","\n","  # compute BPR loss from user, positive item, and negative item embeddings\n","  pos_scores = torch.mul(users_emb, pos_emb).sum(dim=1)\n","  neg_scores = torch.mul(users_emb, neg_emb).sum(dim=1)\n","\n","  bpr_loss = torch.mean(F.softplus(neg_scores - pos_scores))\n","\n","  return bpr_loss, reg_loss"]},{"cell_type":"code","execution_count":165,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718040874174,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"vAmqLNP1L3wm"},"outputs":[],"source":["def get_metrics_pos(user_Embed_wts_pos, item_Embed_wts_pos, n_users_pos, n_items_pos, train_data, test_data, K):\n","  test_user_ids = torch.LongTensor(test_data['user_id_idx'].unique())\n","  # compute the score of all user-item pairs\n","  relevance_score = torch.matmul(user_Embed_wts_pos, torch.transpose(item_Embed_wts_pos,0, 1))\n","\n","  # create dense tensor of all user-item interactions\n","  i = torch.stack((\n","    torch.LongTensor(train_data['user_id_idx'].values),\n","    torch.LongTensor(train_data['item_id_idx'].values)\n","  ))\n","  v = torch.ones((len(train_data)), dtype=torch.float64)\n","  interactions_t = torch.sparse.FloatTensor(i, v, (n_users_pos, n_items_pos))\\\n","      .to_dense().to(device)\n","\n","  # mask out training user-item interactions from metric computation\n","  relevance_score = torch.mul(relevance_score, (1 - interactions_t))\n","\n","  # compute top scoring items for each user\n","  topk_relevance_indices = torch.topk(relevance_score, K).indices\n","  topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy(),columns =['top_indx_'+str(x+1) for x in range(K)])\n","  topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n","  topk_relevance_indices_df['top_rlvnt_itm'] = topk_relevance_indices_df[['top_indx_'+str(x+1) for x in range(K)]].values.tolist()\n","  topk_relevance_indices_df = topk_relevance_indices_df[['user_ID','top_rlvnt_itm']]\n","\n","  test_data_sup3 = test_data[test_data['rating'] >= 3]\n","  test_interacted_items_sup3 = test_data_sup3.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n","\n","  test_data_inf3 = test_data[test_data['rating'] < 3]\n","  test_interacted_items_inf3 = test_data_inf3.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n","\n","  # Ensure all users are included in both TP and FP calculations\n","  all_users = pd.DataFrame({'user_id_idx': test_df['user_id_idx'].unique()})\n","\n","  # Merge with all_users to include all users\n","  test_interacted_items_sup3 = pd.merge(all_users, test_interacted_items_sup3, on='user_id_idx', how='left')\n","  test_interacted_items_inf3 = pd.merge(all_users, test_interacted_items_inf3, on='user_id_idx', how='left')\n","\n","  # Fill NaN values with empty lists\n","  test_interacted_items_sup3['item_id_idx'] = test_interacted_items_sup3['item_id_idx'].apply(lambda x: x if isinstance(x, list) else [])\n","  test_interacted_items_inf3['item_id_idx'] = test_interacted_items_inf3['item_id_idx'].apply(lambda x: x if isinstance(x, list) else [])\n","\n","  # True Positives\n","  TP = pd.merge(test_interacted_items_sup3, topk_relevance_indices_df, how='left', left_on='user_id_idx', right_on='user_ID')\n","  TP['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in zip(TP.item_id_idx, TP.top_rlvnt_itm)]\n","\n","  # False Positives\n","  FP = pd.merge(test_interacted_items_inf3, topk_relevance_indices_df, how='left', left_on='user_id_idx', right_on='user_ID')\n","  FP['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in zip(FP.item_id_idx, FP.top_rlvnt_itm)]\n","\n","  return TP, FP"]},{"cell_type":"code","execution_count":247,"metadata":{"executionInfo":{"elapsed":462,"status":"ok","timestamp":1718043712845,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"GD1fIB0W8a-j"},"outputs":[],"source":["def get_metrics_neg(user_Embed_wts, item_Embed_wts, n_users, n_items, train_data, test_data, K):\n","  test_user_ids = torch.LongTensor(test_data['user_id_idx'].unique())\n","  # compute the score of all user-item pairs\n","  relevance_score = torch.matmul(user_Embed_wts, torch.transpose(item_Embed_wts,0, 1))\n","\n","  # create dense tensor of all user-item interactions\n","  i = torch.stack((\n","    torch.LongTensor(train_df['user_id_idx'].values),\n","    torch.LongTensor(train_df['item_id_idx'].values)\n","  ))\n","  v = torch.ones((len(train_df)), dtype=torch.float64)\n","  interactions_t = torch.sparse.FloatTensor(i, v, (n_users, n_items))\\\n","      .to_dense().to(device)\n","\n","  # mask out training user-item interactions from metric computation\n","  relevance_score = torch.mul(relevance_score, (1 - interactions_t))\n","\n","  # compute top scoring items for each user\n","  topk_relevance_indices = torch.topk(relevance_score, K).indices\n","  topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy(),columns =['top_indx_'+str(x+1) for x in range(K)])\n","  topk_relevance_indices_df['user_ID'] = topk_relevance_indices_df.index\n","  topk_relevance_indices_df['top_rlvnt_itm'] = topk_relevance_indices_df[['top_indx_'+str(x+1) for x in range(K)]].values.tolist()\n","  topk_relevance_indices_df = topk_relevance_indices_df[['user_ID','top_rlvnt_itm']]\n","\n","  test_data_sup3 = test_data[test_data['rating'] > 3]\n","  test_interacted_items_sup3 = test_data_sup3.groupby('user_id_idx')['item_id_idx'].apply(list).reset_index()\n","\n","  # Ensure all users are included in both TP and FP calculations\n","  all_users = pd.DataFrame({'user_id_idx': test_data['user_id_idx'].unique()})\n","\n","  # Merge with all_users to include all users\n","  test_interacted_items_sup3 = pd.merge(all_users, test_interacted_items_sup3, on='user_id_idx', how='left')\n","\n","  # Fill NaN values with empty lists\n","  test_interacted_items_sup3['item_id_idx'] = test_interacted_items_sup3['item_id_idx'].apply(lambda x: x if isinstance(x, list) else [])\n","\n","  # False Negatives\n","  FN = pd.merge(test_interacted_items_sup3, topk_relevance_indices_df, how='left', left_on='user_id_idx', right_on='user_ID')\n","  FN['intrsctn_itm'] = [list(set(a).intersection(b)) for a, b in zip(FN.item_id_idx, FN.top_rlvnt_itm)]\n","\n","  return FN\n"]},{"cell_type":"code","execution_count":258,"metadata":{"executionInfo":{"elapsed":550,"status":"ok","timestamp":1718044271906,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"pzuT5vkS8rrS"},"outputs":[],"source":["def get_recall_accuracy(TP, FP, FN):\n","    # Ensure TP, FP, and FN are lists of lists\n","    assert all(isinstance(i, list) for i in TP), \"TP must be a list of lists\"\n","    assert all(isinstance(i, list) for i in FP), \"FP must be a list of lists\"\n","    assert all(isinstance(i, list) for i in FN), \"FN must be a list of lists\"\n","\n","    # Calculate recall for each user\n","    recall = [\n","        len(TP[i]) / (len(TP[i]) + len(FN[i])) if (len(TP[i]) + len(FN[i])) > 0 else 0\n","        for i in range(len(TP))\n","    ]\n","\n","    # Calculate precision for each user\n","    precision = [\n","        len(TP[i]) / (len(TP[i]) + len(FP[i])) if (len(TP[i]) + len(FP[i])) > 0 else 0\n","        for i in range(len(TP))\n","    ]\n","\n","    return np.mean(recall), np.mean(precision)"]},{"cell_type":"markdown","metadata":{"id":"_qOC3fF9m6cH"},"source":["## Train and evaluate models\n","\n","Now that we've implemented both LightGCN and NGCF in PyG, we can train and evaluate their performance!"]},{"cell_type":"code","execution_count":168,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718040874804,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"MZtgfxxIm5nL"},"outputs":[],"source":["latent_dim = 64\n","n_layers = 3\n","\n","EPOCHS = 10\n","BATCH_SIZE = 4096\n","DECAY = 0.0001\n","LR = 0.005\n","K = 20"]},{"cell_type":"code","execution_count":169,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718040874804,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"B5HB_FX5pdgv"},"outputs":[],"source":["def train_and_eval(model, optimizer, train_df):\n","\n","  for epoch in tqdm(range(EPOCHS)):\n","      n_batch = int(len(train_df)/BATCH_SIZE)\n","\n","      final_loss_list = []\n","      bpr_loss_list = []\n","      reg_loss_list = []\n","\n","      model.train()\n","      for batch_idx in tqdm(range(n_batch)):\n","\n","          optimizer.zero_grad()\n","\n","          users, pos_items, neg_items = data_loader(train_df, BATCH_SIZE, n_users, n_items)\n","          users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0 = model.encode_minibatch(users, pos_items, neg_items, train_edge_index)\n","\n","          bpr_loss, reg_loss = compute_bpr_loss(\n","            users, users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0\n","          )\n","          reg_loss = DECAY * reg_loss\n","          final_loss = bpr_loss + reg_loss\n","\n","          final_loss.backward()\n","          optimizer.step()\n","\n","          final_loss_list.append(final_loss.item())\n","          bpr_loss_list.append(bpr_loss.item())\n","          reg_loss_list.append(reg_loss.item())\n","\n","      torch.save(model.state_dict(), f'/content/drive/MyDrive/Colab/NML/model_epoch{epoch}_2.pth')\n"]},{"cell_type":"markdown","metadata":{"id":"Z4xJSiBiznki"},"source":["### Train and eval LightGCN"]},{"cell_type":"markdown","metadata":{},"source":["We train two LightGCN models, one for positive ratings and one for negative ratings. We then evaluate the performance of the models on the test set."]},{"cell_type":"code","execution_count":170,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1718040875510,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"eKBv9eXongux","outputId":"fbe5fd02-2c6f-4398-c002-8ddf4047369f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of Learnable Embedding :  [torch.Size([56254, 64])]\n"]}],"source":["lightgcn_neg = RecSysGNN(\n","  latent_dim=latent_dim,\n","  num_layers=n_layers,\n","  num_users=n_users,\n","  num_items=n_items,\n","  model='LightGCN'\n",")\n","\n","lightgcn_neg.load_state_dict(torch.load('/content/drive/MyDrive/Colab/NML/model_neg.pth',  map_location=device))\n","lightgcn_neg.to(device)\n","\n","# Train the model\n","optimizer = torch.optim.Adam(lightgcn_neg.parameters(), lr=LR)\n","print(\"Size of Learnable Embedding : \", [x.shape for x in list(lightgcn_neg.parameters())])\n","train_and_eval(lightgcn_neg, optimizer, train_df)"]},{"cell_type":"code","execution_count":172,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1718040875511,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"ciSQkgIG9c9R","outputId":"5b8dac2e-5f15-4d76-9373-d9346930b28d"},"outputs":[{"data":{"text/plain":["RecSysGNN(\n","  (embedding): Embedding(39998, 64)\n","  (convs): ModuleList(\n","    (0-2): 3 x LightGCNConv()\n","  )\n",")"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["lightgcn_pos = RecSysGNN(\n","  latent_dim=latent_dim,\n","  num_layers=n_layers,\n","  num_users=n_users_pos,\n","  num_items=n_items_pos,\n","  model='LightGCN'\n",")\n","\n","lightgcn_pos.load_state_dict(torch.load('/content/drive/MyDrive/Colab/NML/model_pos.pth',  map_location=device))\n","lightgcn_pos.to(device)"]},{"cell_type":"markdown","metadata":{"id":"iwgskJrzb1M5"},"source":["To choose the best K we compute the median of ratings for positive and negatives ratings and we take them as `K_pos` and `K_neg`. "]},{"cell_type":"code","execution_count":268,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1003,"status":"ok","timestamp":1718044762832,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"b3hZZHAabTci","outputId":"886887f5-ee6b-4794-ac07-53b4ef3c4927"},"outputs":[{"name":"stdout","output_type":"stream","text":["K_neg : 6\n"]}],"source":["groups_neg = df.groupby('user_id_idx')['item_id_idx'].apply(list)\n","groups_neg = [len(x) for x in groups_neg]\n","K_neg = np.median(groups_neg).astype(int)\n","print('K_neg :', K_neg)"]},{"cell_type":"code","execution_count":269,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1001,"status":"ok","timestamp":1718044764283,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"rjJM5HeQbn0L","outputId":"8ae86b3f-3fa3-434e-d566-684bf8e2650e"},"outputs":[{"name":"stdout","output_type":"stream","text":["K_pos : 83\n"]}],"source":["groups_pos = df_pos.groupby('user_id_idx')['item_id_idx'].apply(list)\n","groups_pos = [len(x) for x in groups_pos]\n","K_pos = np.median(groups_pos).astype(int)\n","print('K_pos :', K_pos)"]},{"cell_type":"markdown","metadata":{},"source":["Now calculate the precision and recall for the sum of the positive and negative ratings."]},{"cell_type":"code","execution_count":270,"metadata":{"executionInfo":{"elapsed":13331,"status":"ok","timestamp":1718044777610,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"iuCwr3ONL9FH"},"outputs":[],"source":["# Evaluate the positive model\n","_, out = lightgcn_pos(train_edge_index_pos)\n","final_user_Embed, final_item_Embed = torch.split(out, (n_users_pos, n_items_pos))\n","TP,FP= get_metrics_pos( final_user_Embed, final_item_Embed, n_users_pos, n_items_pos, train_df_pos, test_df, K_pos)\n","\n","# Evaluate the negative model\n","_, out = lightgcn_neg(train_edge_index)\n","final_user_Embed, final_item_Embed = torch.split(out, (n_users, n_items))\n","FN= get_metrics_neg( final_user_Embed, final_item_Embed, n_users, n_items, train_df, test_df, K_neg)"]},{"cell_type":"markdown","metadata":{},"source":["Now to calculate the precision and recall for the sum of the positive and negative ratings, we need to find the users that are present in the two training sets and the test set, to calculate the precision and recall for each user. Then we calculate the average precision and recall for all users."]},{"cell_type":"code","execution_count":271,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1718044789637,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"z3qfoEvqN9ex"},"outputs":[],"source":["TP.rename(columns={'intrsctn_itm': 'TP'}, inplace=True)\n","FP.rename(columns={'intrsctn_itm': 'FP'}, inplace=True)\n","FN.rename(columns={'intrsctn_itm': 'FN'}, inplace=True)\n","\n","merged_df = pd.merge(TP, FP, on='user_ID', how='inner')\n","merged_df = pd.merge(merged_df, FN, on='user_ID', how='inner')\n","\n","TP = merged_df['TP']\n","FP = merged_df['FP']\n","FN = merged_df['FN']\n"]},{"cell_type":"code","execution_count":272,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1718044805309,"user":{"displayName":"Joanna Wolski","userId":"17851328151677993349"},"user_tz":-120},"id":"k3XLX_qrPLGW","outputId":"f257fd89-364e-4337-c7f7-738646f88831"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6044794789533449\n","0.6088721166190417\n"]}],"source":["recall, precision = get_recall_accuracy(TP,FP,FN)\n","print(recall)\n","print(precision)"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the recall and precision are about the same, but are not really high. We could train on more epoch to improve the results."]},{"cell_type":"markdown","metadata":{},"source":["this method is inspire by the blog page: \n","\n","https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377\n","\n","Paper References\n","\n","    Harper, F. Maxwell, and Konstan, Joseph A. “The MovieLensDatasets: History and Context.” ACM Transactions on Interactive Intelligence Systems (TiiS) 5, 4. 2015.\n","\n","    He, Xiangnan, et al. “LightGCN: Simplifying and powering graph convolution network for recommendation.” Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020.\n","    \n","    Wang, Xiang, et al. “Neural graph collaborative filtering.” Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
